{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WfrCFmLHxYu"
      },
      "source": [
        "# CS3033/CS6405 - Data Mining - Second Assignment\n",
        "\n",
        "### Submission\n",
        "\n",
        "This assignment is **due on 06/04/22 at 23:59**. You should submit a single .ipnyb file with your python code and analysis electronically via Canvas.\n",
        "Please note that this assignment will account for 25 Marks of your module grade.\n",
        "\n",
        "### Declaration\n",
        "\n",
        "By submitting this assignment. I agree to the following:\n",
        "\n",
        "<font color=\"red\">“I have read and understand the UCC academic policy on plagiarism, and agree to the requirements set out thereby in relation to plagiarism and referencing. I confirm that I have referenced and acknowledged properly all sources used in the preparation of this assignment.\n",
        "I declare that this assignment is entirely my own work based on my personal study. I further declare that I have not engaged the services of another to either assist me in, or complete this assignment”</font>\n",
        "\n",
        "### Objective\n",
        "\n",
        "The Boolean satisfiability (SAT) problem consists in determining whether a Boolean formula F is satisfiable or not. F is represented by a pair (X, C), where X is a set of Boolean variables and C is a set of clauses in Conjunctive Normal Form (CNF). Each clause is a disjunction of literals (a variable or its negation). This problem is one of the most widely studied combinatorial problems in computer science. It is the classic NP-complete problem. Over the past number of decades, a significant amount of research work has focused on solving SAT problems with both complete and incomplete solvers.\n",
        "\n",
        "Recent advances in supervised learning have provided powerful techniques for classifying problems. In this project, we see the SAT problem as a classification problem. Given a Boolean formula (represented by a vector of features), we are asked to predict if it is satisfiable or not.\n",
        "\n",
        "In this project, we represent SAT problems with a vector of 327 features with general information about the problem, e.g., number of variables, number of clauses, fraction of horn clauses in the problem, etc. There is no need to understand the features to be able to complete the assignment.\n",
        "\n",
        "The dataset is available at:\n",
        "https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_train.csv\n",
        "\n",
        "This is original unpublished data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYoMg0EZIrNd"
      },
      "source": [
        "## New classifier (10 Marks)\n",
        "\n",
        "Replicate the previous task for a classifier that we did not cover in class. So different than K-NN and decision trees. Briefly describe your choice.\n",
        "Try to create the best model for the given dataset.\n",
        "Save your best model into your github. And create a single code cell that loads it and evaluate it on the following test dataset:\n",
        "https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_test.csv\n",
        "\n",
        "This link currently contains a sample of the training set. The real test set will be released after the submission. I should be able to run the code cell independently, load all the libraries you need as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QRJXrY2hI32F"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1929, 328)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/andvise/DataAnalyticsDatasets/main/dm_assignment2/sat_dataset_train.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1929 entries, 0 to 1928\n",
            "Columns: 328 entries, c to target\n",
            "dtypes: float64(237), int64(91)\n",
            "memory usage: 4.8 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>v</th>\n",
              "      <th>clauses_vars_ratio</th>\n",
              "      <th>vars_clauses_ratio</th>\n",
              "      <th>vcg_var_mean</th>\n",
              "      <th>vcg_var_coeff</th>\n",
              "      <th>vcg_var_min</th>\n",
              "      <th>vcg_var_max</th>\n",
              "      <th>vcg_var_entropy</th>\n",
              "      <th>vcg_clause_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>rwh_0_max</th>\n",
              "      <th>rwh_1_mean</th>\n",
              "      <th>rwh_1_coeff</th>\n",
              "      <th>rwh_1_min</th>\n",
              "      <th>rwh_1_max</th>\n",
              "      <th>rwh_2_mean</th>\n",
              "      <th>rwh_2_coeff</th>\n",
              "      <th>rwh_2_min</th>\n",
              "      <th>rwh_2_max</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>420</td>\n",
              "      <td>10</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>...</td>\n",
              "      <td>78750.0</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.875000e-06</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230</td>\n",
              "      <td>20</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.137826</td>\n",
              "      <td>0.089281</td>\n",
              "      <td>0.117391</td>\n",
              "      <td>0.160870</td>\n",
              "      <td>2.180946</td>\n",
              "      <td>0.137826</td>\n",
              "      <td>...</td>\n",
              "      <td>6646875.0</td>\n",
              "      <td>17433.722184</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.981244e-12</td>\n",
              "      <td>34867.444369</td>\n",
              "      <td>1.727721e+04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.358551e-53</td>\n",
              "      <td>3.455442e+04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>240</td>\n",
              "      <td>16</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>...</td>\n",
              "      <td>500000.0</td>\n",
              "      <td>1525.878932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1525.878932</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>424</td>\n",
              "      <td>30</td>\n",
              "      <td>14.133333</td>\n",
              "      <td>0.070755</td>\n",
              "      <td>0.226415</td>\n",
              "      <td>0.485913</td>\n",
              "      <td>0.056604</td>\n",
              "      <td>0.452830</td>\n",
              "      <td>2.220088</td>\n",
              "      <td>0.226415</td>\n",
              "      <td>...</td>\n",
              "      <td>87500.0</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.535723e-14</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>8.218628e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.499676e-61</td>\n",
              "      <td>1.643726e-06</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>162</td>\n",
              "      <td>19</td>\n",
              "      <td>8.526316</td>\n",
              "      <td>0.117284</td>\n",
              "      <td>0.139701</td>\n",
              "      <td>0.121821</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>1.940843</td>\n",
              "      <td>0.139701</td>\n",
              "      <td>...</td>\n",
              "      <td>5859400.0</td>\n",
              "      <td>16591.494310</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.912726e-42</td>\n",
              "      <td>33182.988621</td>\n",
              "      <td>1.665903e+04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.331807e+04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 328 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     c   v  clauses_vars_ratio  vars_clauses_ratio  vcg_var_mean  \\\n",
              "0  420  10           42.000000            0.023810      0.600000   \n",
              "1  230  20           11.500000            0.086957      0.137826   \n",
              "2  240  16           15.000000            0.066667      0.300000   \n",
              "3  424  30           14.133333            0.070755      0.226415   \n",
              "4  162  19            8.526316            0.117284      0.139701   \n",
              "\n",
              "   vcg_var_coeff  vcg_var_min  vcg_var_max  vcg_var_entropy  vcg_clause_mean  \\\n",
              "0       0.000000     0.600000     0.600000         0.000000         0.600000   \n",
              "1       0.089281     0.117391     0.160870         2.180946         0.137826   \n",
              "2       0.000000     0.300000     0.300000         0.000000         0.300000   \n",
              "3       0.485913     0.056604     0.452830         2.220088         0.226415   \n",
              "4       0.121821     0.111111     0.185185         1.940843         0.139701   \n",
              "\n",
              "   ...  rwh_0_max    rwh_1_mean  rwh_1_coeff     rwh_1_min     rwh_1_max  \\\n",
              "0  ...    78750.0      0.000008          0.0  7.875000e-06      0.000008   \n",
              "1  ...  6646875.0  17433.722184          1.0  2.981244e-12  34867.444369   \n",
              "2  ...   500000.0   1525.878932          0.0  1.525879e+03   1525.878932   \n",
              "3  ...    87500.0      0.000122          1.0  6.535723e-14      0.000245   \n",
              "4  ...  5859400.0  16591.494310          1.0  6.912726e-42  33182.988621   \n",
              "\n",
              "     rwh_2_mean  rwh_2_coeff     rwh_2_min     rwh_2_max  target  \n",
              "0  2.385082e-21          0.0  2.385082e-21  2.385082e-21       1  \n",
              "1  1.727721e+04          1.0  1.358551e-53  3.455442e+04       0  \n",
              "2  1.525879e+03          0.0  1.525879e+03  1.525879e+03       1  \n",
              "3  8.218628e-07          1.0  1.499676e-61  1.643726e-06       0  \n",
              "4  1.665903e+04          1.0  0.000000e+00  3.331807e+04       1  \n",
              "\n",
              "[5 rows x 328 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN values in dataset: True\n",
            "Inf values in dataset: True\n"
          ]
        }
      ],
      "source": [
        "# Check if there are any NaN or infintie values in the dataset\n",
        "def check_nan_and_infinite_values(df):\n",
        "    print('NaN values in dataset:', np.any(np.isnan(df)))\n",
        "    print('Inf values in dataset:', not np.all(np.isfinite(df)))\n",
        "\n",
        "check_nan_and_infinite_values(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN values in dataset: False\n",
            "Inf values in dataset: False\n"
          ]
        }
      ],
      "source": [
        "# Since there are NaN anf infinite values, we replace them with 0. \n",
        "# This is necessary to do as otherwise the model will throw an error when we start training \n",
        "\n",
        "df = df.replace([np.inf, -np.inf, np.nan], 0)\n",
        "\n",
        "# Hence, no more NaN and inf values. \n",
        "check_nan_and_infinite_values(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SVM model using default parameters\n",
        "\n",
        "# Splitting dataset into train, test with 70, 30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['target']) , df['target'], test_size=0.3)\n",
        "\n",
        "# Declaring default SVC classifier model\n",
        "svm = SVC()\n",
        "\n",
        "# Fitting classifier with training data\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "from sklearn import linear_model\n",
        "model = linear_model.LinearRegression()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVM model with default parameters: 0.5284974093264249\n"
          ]
        }
      ],
      "source": [
        "# Performing predictions with test data\n",
        "y_preds = svm.predict(X_test)\n",
        "print('Accuracy for SVM model with default parameters:', accuracy_score(y_test, y_preds))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1929, 327)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feature Normalization using `Standard Scaling`\n",
        "\n",
        "# Copying df into a new variable\n",
        "df2 = df\n",
        "\n",
        "# Scaling all columns of df except `target` column \n",
        "df2 = StandardScaler().fit_transform(df2.drop(columns=['target']))\n",
        "\n",
        "# Convert the scaled df from dtype array to dtype dataframe\n",
        "df2 = pd.DataFrame(df2, columns=[df.columns.drop('target')])\n",
        "\n",
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>v</th>\n",
              "      <th>clauses_vars_ratio</th>\n",
              "      <th>vars_clauses_ratio</th>\n",
              "      <th>vcg_var_mean</th>\n",
              "      <th>vcg_var_coeff</th>\n",
              "      <th>vcg_var_min</th>\n",
              "      <th>vcg_var_max</th>\n",
              "      <th>vcg_var_entropy</th>\n",
              "      <th>vcg_clause_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>rwh_0_min</th>\n",
              "      <th>rwh_0_max</th>\n",
              "      <th>rwh_1_mean</th>\n",
              "      <th>rwh_1_coeff</th>\n",
              "      <th>rwh_1_min</th>\n",
              "      <th>rwh_1_max</th>\n",
              "      <th>rwh_2_mean</th>\n",
              "      <th>rwh_2_coeff</th>\n",
              "      <th>rwh_2_min</th>\n",
              "      <th>rwh_2_max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.289024</td>\n",
              "      <td>-0.943549</td>\n",
              "      <td>3.799785</td>\n",
              "      <td>-1.311479</td>\n",
              "      <td>4.718609</td>\n",
              "      <td>-1.107531</td>\n",
              "      <td>5.832823</td>\n",
              "      <td>2.807536</td>\n",
              "      <td>-1.957152</td>\n",
              "      <td>4.718609</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.188820</td>\n",
              "      <td>-0.794704</td>\n",
              "      <td>-0.329846</td>\n",
              "      <td>-2.446825</td>\n",
              "      <td>-0.120963</td>\n",
              "      <td>-0.334298</td>\n",
              "      <td>-0.375740</td>\n",
              "      <td>-2.647376</td>\n",
              "      <td>-0.129158</td>\n",
              "      <td>-0.370523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.714431</td>\n",
              "      <td>-0.745699</td>\n",
              "      <td>0.052469</td>\n",
              "      <td>-0.562237</td>\n",
              "      <td>0.257936</td>\n",
              "      <td>-0.636490</td>\n",
              "      <td>0.486160</td>\n",
              "      <td>-0.002255</td>\n",
              "      <td>0.470293</td>\n",
              "      <td>0.257936</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.304107</td>\n",
              "      <td>0.415544</td>\n",
              "      <td>0.335329</td>\n",
              "      <td>0.442685</td>\n",
              "      <td>-0.120963</td>\n",
              "      <td>0.390724</td>\n",
              "      <td>0.020649</td>\n",
              "      <td>0.408452</td>\n",
              "      <td>-0.129158</td>\n",
              "      <td>0.036323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.692041</td>\n",
              "      <td>-0.824839</td>\n",
              "      <td>0.482489</td>\n",
              "      <td>-0.802977</td>\n",
              "      <td>1.823158</td>\n",
              "      <td>-1.107531</td>\n",
              "      <td>2.509222</td>\n",
              "      <td>0.887976</td>\n",
              "      <td>-1.957152</td>\n",
              "      <td>1.823158</td>\n",
              "      <td>...</td>\n",
              "      <td>0.906215</td>\n",
              "      <td>-0.717084</td>\n",
              "      <td>-0.271627</td>\n",
              "      <td>-2.446825</td>\n",
              "      <td>0.031191</td>\n",
              "      <td>-0.302569</td>\n",
              "      <td>-0.340731</td>\n",
              "      <td>-2.647376</td>\n",
              "      <td>0.024214</td>\n",
              "      <td>-0.352557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.280068</td>\n",
              "      <td>-0.547848</td>\n",
              "      <td>0.376007</td>\n",
              "      <td>-0.754472</td>\n",
              "      <td>1.112953</td>\n",
              "      <td>1.456128</td>\n",
              "      <td>-0.187285</td>\n",
              "      <td>1.865865</td>\n",
              "      <td>0.513860</td>\n",
              "      <td>1.112953</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.357137</td>\n",
              "      <td>-0.793092</td>\n",
              "      <td>-0.329846</td>\n",
              "      <td>0.442685</td>\n",
              "      <td>-0.120963</td>\n",
              "      <td>-0.334298</td>\n",
              "      <td>-0.375740</td>\n",
              "      <td>0.408452</td>\n",
              "      <td>-0.129158</td>\n",
              "      <td>-0.370523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.866682</td>\n",
              "      <td>-0.765484</td>\n",
              "      <td>-0.312887</td>\n",
              "      <td>-0.202401</td>\n",
              "      <td>0.276032</td>\n",
              "      <td>-0.464805</td>\n",
              "      <td>0.416584</td>\n",
              "      <td>0.153330</td>\n",
              "      <td>0.203053</td>\n",
              "      <td>0.276032</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.393140</td>\n",
              "      <td>0.270443</td>\n",
              "      <td>0.303194</td>\n",
              "      <td>0.442685</td>\n",
              "      <td>-0.120963</td>\n",
              "      <td>0.355698</td>\n",
              "      <td>0.006466</td>\n",
              "      <td>0.408452</td>\n",
              "      <td>-0.129158</td>\n",
              "      <td>0.021767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 327 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          c         v clauses_vars_ratio vars_clauses_ratio vcg_var_mean  \\\n",
              "0 -0.289024 -0.943549           3.799785          -1.311479     4.718609   \n",
              "1 -0.714431 -0.745699           0.052469          -0.562237     0.257936   \n",
              "2 -0.692041 -0.824839           0.482489          -0.802977     1.823158   \n",
              "3 -0.280068 -0.547848           0.376007          -0.754472     1.112953   \n",
              "4 -0.866682 -0.765484          -0.312887          -0.202401     0.276032   \n",
              "\n",
              "  vcg_var_coeff vcg_var_min vcg_var_max vcg_var_entropy vcg_clause_mean  ...  \\\n",
              "0     -1.107531    5.832823    2.807536       -1.957152        4.718609  ...   \n",
              "1     -0.636490    0.486160   -0.002255        0.470293        0.257936  ...   \n",
              "2     -1.107531    2.509222    0.887976       -1.957152        1.823158  ...   \n",
              "3      1.456128   -0.187285    1.865865        0.513860        1.112953  ...   \n",
              "4     -0.464805    0.416584    0.153330        0.203053        0.276032  ...   \n",
              "\n",
              "  rwh_0_min rwh_0_max rwh_1_mean rwh_1_coeff rwh_1_min rwh_1_max rwh_2_mean  \\\n",
              "0 -0.188820 -0.794704  -0.329846   -2.446825 -0.120963 -0.334298  -0.375740   \n",
              "1 -0.304107  0.415544   0.335329    0.442685 -0.120963  0.390724   0.020649   \n",
              "2  0.906215 -0.717084  -0.271627   -2.446825  0.031191 -0.302569  -0.340731   \n",
              "3 -0.357137 -0.793092  -0.329846    0.442685 -0.120963 -0.334298  -0.375740   \n",
              "4 -0.393140  0.270443   0.303194    0.442685 -0.120963  0.355698   0.006466   \n",
              "\n",
              "  rwh_2_coeff rwh_2_min rwh_2_max  \n",
              "0   -2.647376 -0.129158 -0.370523  \n",
              "1    0.408452 -0.129158  0.036323  \n",
              "2   -2.647376  0.024214 -0.352557  \n",
              "3    0.408452 -0.129158 -0.370523  \n",
              "4    0.408452 -0.129158  0.021767  \n",
              "\n",
              "[5 rows x 327 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df with scaled features\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hold-out method for splitting normalized df\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(df2, df['target'], test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PCA(n_components=0.9)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feature Reduction using PCA\n",
        "\n",
        "# Retaining 90% of explained variance\n",
        "pca = PCA(n_components=0.9)   \n",
        "\n",
        "# Extracting the columns onto the scaled \n",
        "pca.fit(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Transforming the train set  \n",
        "X_train2 = pca.transform(X_train2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1350, 19)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Transforming the test set \n",
        "X_test2 = pca.transform(X_test2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(579, 19)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        }
      ],
      "source": [
        "#SVM using Cross-Validation and HyperParameter tuning\n",
        "\n",
        "# Describing hyperparameters for Grid Search ## Takes roughly 1min \n",
        "param_grid = { \n",
        "    'C':[0.1,1,100],\n",
        "    'kernel':['rbf','linear'],\n",
        "    'degree':[1,3,5],\n",
        "    'gamma': [0.001, 0.0001]\n",
        "}\n",
        "# Declaring GridSearch with appropriate model and parameters\n",
        "grid = GridSearchCV(SVC(),param_grid,  scoring='accuracy', return_train_score=False, verbose=1)\n",
        "\n",
        "# Applying Grid Search and Cross Validation\n",
        "grid_search = grid.fit(X_train2, y_train2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'C': 100, 'degree': 1, 'gamma': 0.001, 'kernel': 'rbf'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the best parameters found\n",
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.928888888888889"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the best score achieved with the best parameter\n",
        "grid_search.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Declare SVM with the best parameters found in Grid Search  \n",
        "SVM_test = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(C=100, degree=1, gamma=0.001)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train best model with scaled training data\n",
        "SVM_test.fit(X_train2, y_train2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVM model with Grid Search and CV: 0.9326424870466321\n"
          ]
        }
      ],
      "source": [
        "# Make predictions with scaled test data\n",
        "y_preds2 = SVM_test.predict(X_test2) \n",
        "print('Accuracy for SVM model with Grid Search and CV:', accuracy_score(y_test2, y_preds2)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['model.sav']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Add in save model code here\n",
        "\n",
        "import joblib\n",
        "\n",
        "file = 'model.sav'\n",
        "\n",
        "joblib.dump(model, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CS3033/CS6405 - Data Mining - Second Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
